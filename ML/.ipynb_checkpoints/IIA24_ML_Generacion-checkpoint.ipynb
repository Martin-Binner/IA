{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8Sa4wRPHxZL"
   },
   "source": [
    "# IIA 2024 - Aprendizaje Automatizado\n",
    "\n",
    "## Introducción a Jupyter Notebooks y Generación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDkNZ_jzG71j"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDufflloIHHo"
   },
   "source": [
    "## Diagonales\n",
    "\n",
    "Generar n datos con d inputs:\n",
    "\n",
    "  - n/2 pertenecientes a la categoría 0. Esta clase corresponde a puntos generados al azar, provenientes de una distribución normal, con centro en el (-1, -1, -1, ... , -1) y matriz de covarianza diagonal, con desviación estándar igual a C * SQRT(d).\n",
    "  - n/2 pertenecientes a la categoría 1. Esta clase corresponde a puntos generados al azar, provenientes de una distribución normal, con centro en el (1, 1, 1, ... ,1) y matriz de covarianza diagonal, con desviación estándar igual a C * SQRT(d).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFZtOrGRIOrW"
   },
   "outputs": [],
   "source": [
    "def diagonales(n, d, C):\n",
    "    mean0 = np.full(d, -1)\n",
    "    mean1 = np.full(d, 1)\n",
    "\n",
    "    desv = C * math.sqrt(d)\n",
    "    covarianza = np.diag(np.full(d, desv))\n",
    "\n",
    "    input0 = np.random.multivariate_normal(mean0, covarianza, n//2)\n",
    "    input1 = np.random.multivariate_normal(mean1, covarianza, (n-n//2))\n",
    "\n",
    "    output0 = np.full(n//2, 0)\n",
    "    output1 = np.full(n-n//2, 1)\n",
    "\n",
    "    inputs = np.concatenate([input0, input1])\n",
    "    outputs = np.concatenate([output0, output1])\n",
    "    \n",
    "    return pd.DataFrame({\"input\" : inputs.tolist(), \"output\" : outputs})\n",
    "\n",
    "diagonales(10, 2, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46vC4fcQJLMJ"
   },
   "source": [
    "Verificamos ahora los datos generados, mostrándolos con matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkorNOQcJQcH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diag_df = diagonales(200, 2, 0.01)\n",
    "\n",
    "# diferenciar entre clase 0 y clase 1\n",
    "c0 = diag_df[diag_df['output'] == 0]\n",
    "c1 = diag_df[diag_df['output'] == 1]\n",
    "\n",
    "xs0 = [e[0] for e in c0['input']]\n",
    "ys0 = [e[1] for e in c0['input']]\n",
    "xs1 = [e[0] for e in c1['input']]\n",
    "ys1 = [e[1] for e in c1['input']]\n",
    "\n",
    "import itertools\n",
    "\n",
    "colors = itertools.cycle([\"g\",\"b\",\"a\"]);\n",
    "plt.scatter(xs0, ys0, color=next(colors))\n",
    "plt.scatter(xs1, ys1, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dp3dOwR9IPFb"
   },
   "source": [
    "## Paralelas\n",
    "\n",
    "Igual al punto anterior, pero las distribuciones tienen centro en el ( 1, 0, 0, .... , 0 ) y en el ( -1, 0, 0, .... , 0 ), respectivamente y la desviación estandar es igual a C independientemente de d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSFCiGvMIT-y"
   },
   "outputs": [],
   "source": [
    "def paralelas(n, d, C):\n",
    "    mean0 = np.zeros(d)\n",
    "    mean1 = np.zeros(d)\n",
    "    mean0[0] = 1\n",
    "    mean1[0] = -1\n",
    "\n",
    "    desv = C \n",
    "    covarianza = np.diag(np.full(d, desv ** 2))\n",
    "\n",
    "    input0 = np.random.multivariate_normal(mean0, covarianza, n//2)\n",
    "    input1 = np.random.multivariate_normal(mean1, covarianza, (n-n//2))\n",
    "\n",
    "    output0 = np.full(n//2, 0)\n",
    "    output1 = np.full(n-n//2, 1)\n",
    "\n",
    "    inputs = np.concatenate([input0, input1])\n",
    "    outputs = np.concatenate([output0, output1])\n",
    "    \n",
    "    return pd.DataFrame({\"input\" : inputs.tolist(), \"output\" : outputs})\n",
    "\n",
    "paralelas(10, 2, 0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_df = paralelas(20000, 2, 0.01)\n",
    "\n",
    "# diferenciar entre clase 0 y clase 1\n",
    "c0 = diag_df[diag_df['output'] == 0]\n",
    "c1 = diag_df[diag_df['output'] == 1]\n",
    "\n",
    "xs0 = [e[0] for e in c0['input']]\n",
    "ys0 = [e[1] for e in c0['input']]\n",
    "xs1 = [e[0] for e in c1['input']]\n",
    "ys1 = [e[1] for e in c1['input']]\n",
    "\n",
    "import itertools\n",
    "\n",
    "colors = itertools.cycle([\"r\",\"b\",\"a\"]);\n",
    "plt.scatter(xs0, ys0, color=next(colors))\n",
    "plt.scatter(xs1, ys1, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghtUorLAIUwD"
   },
   "source": [
    "## Espirales\n",
    "\n",
    "Generar n datos. De los n puntos generados, n/2 deben pertenecer a cada clase.\n",
    "\n",
    "Los datos tienen 2 inputs, x e y, que corresponden a puntos generados al azar con una distribución UNIFORME (en dicho sistema de referencia x-y) dentro de un circulo de radio 1.\n",
    "\n",
    "El output es binario, correspondiendo la clase 0 a los puntos que se encuentran entre las curvas ro = theta/4pi y ro = (theta + pi)/4pi (en polares) y la clase 1 al resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lwc3ussYI7aE"
   },
   "outputs": [],
   "source": [
    "def checkFactor(r, theta, factor):\n",
    "    x = (theta + factor*2*np.pi)\n",
    "    return (r*4 - 1)*np.pi < x and x < r*4*np.pi\n",
    "\n",
    "def generaPunto(radius=1):\n",
    "    # Generar un ángulo aleatorio entre 0 y 2π\n",
    "    theta = np.random.uniform(0, 2 * np.pi)\n",
    "    \n",
    "    # Generar un radio aleatorio con una distribución uniforme en el área del círculo\n",
    "    r = radius * np.sqrt(np.random.uniform(0, 1))\n",
    "\n",
    "    bool = True\n",
    "    # Convertir coordenadas polares (r, theta) a coordenadas cartesianas (x, y)\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "    \n",
    "    if checkFactor(r, theta,1) or checkFactor(r,theta,0) or checkFactor(r, theta, -1):\n",
    "        return (True, np.array([x, y]))\n",
    "    else:\n",
    "        return (False, np.array([x,y]))\n",
    "\n",
    "def generaInEspiral(k, bool):\n",
    "    puntos = []\n",
    "    contador = k\n",
    "    while contador != 0:\n",
    "        punto = generaPunto()\n",
    "        if bool == punto[0]:\n",
    "            puntos.append(punto[1])\n",
    "            contador -= 1\n",
    "    return np.array(puntos)\n",
    "\n",
    "def espirales(n):\n",
    "    input0 = generaInEspiral(n//2, True)\n",
    "    input1 = generaInEspiral(n-n//2, False)\n",
    "\n",
    "    output0 = np.full(n//2, 0)\n",
    "    output1 = np.full(n-n//2, 1)\n",
    "\n",
    "    inputs = np.concatenate([input0, input1])\n",
    "    outputs = np.concatenate([output0, output1])\n",
    "    \n",
    "    return pd.DataFrame({\"input\" : inputs.tolist(), \"output\" : outputs})\n",
    "\n",
    "espirales(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_df = espirales(2500)\n",
    "\n",
    "# diferenciar entre clase 0 y clase 1\n",
    "c0 = diag_df[diag_df['output'] == 0]\n",
    "c1 = diag_df[diag_df['output'] == 1]\n",
    "\n",
    "xs0 = [e[0] for e in c0['input']]\n",
    "ys0 = [e[1] for e in c0['input']]\n",
    "xs1 = [e[0] for e in c1['input']]\n",
    "ys1 = [e[1] for e in c1['input']]\n",
    "\n",
    "import itertools\n",
    "\n",
    "colors = itertools.cycle([\"r\",\"b\",\"a\"]);\n",
    "plt.scatter(xs0, ys0, color=next(colors))\n",
    "plt.scatter(xs1, ys1, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\",min_impurity_decrease=0.002,random_state=0,min_samples_leaf=5)\n",
    "clf.fit(X_train, y_train)\n",
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "Genere tres conjuntos de datos de entrenamiento correspondientes al problema de las espirales anidadas de la práctica 0, uno de longitud 150, otro de 600 y un tercero de 3000. Genere un conjunto de test de longitud 10000. A partir de cada uno de los conjuntos de entrenamiento, entrene el árbol de decisión correspondiente y grafique las predicciones sobre el conjunto de test. Comente los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTreeClassifier(s):\n",
    "    Xinput = np.array(s['input'].tolist())\n",
    "    youtput = np.array(s['output'])\n",
    "    Xinput_train, Xinput_test, youtput_train, youtput_test = train_test_split(Xinput, youtput, random_state=0)\n",
    "    clf1 = DecisionTreeClassifier(criterion=\"entropy\",min_impurity_decrease=0.002,random_state=0,min_samples_leaf=5)\n",
    "    clf1.fit(Xinput_train, youtput_train)\n",
    "    plot_tree(clf1)\n",
    "    return (Xinput_test, youtput_test), clf1\n",
    "\n",
    "sets =[espirales(i) for i in [150,600,3000]]\n",
    "_,tree150 = toTreeClassifier(sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tree600 = toTreeClassifier(sets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tree3000 = toTreeClassifier(sets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printData(diag_df):\n",
    "    # diferenciar entre clase 0 y clase 1\n",
    "    c0 = diag_df[diag_df['output'] == 0]\n",
    "    c1 = diag_df[diag_df['output'] == 1]\n",
    "\n",
    "    xs0 = [e[0] for e in c0['input']]\n",
    "    ys0 = [e[1] for e in c0['input']]\n",
    "    xs1 = [e[0] for e in c1['input']]\n",
    "    ys1 = [e[1] for e in c1['input']]\n",
    "\n",
    "    plt.scatter(xs0, ys0, color='yellow')\n",
    "    plt.scatter(xs1, ys1, color='blue')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparationDataFrame(test, tree):\n",
    "    predictTree = tree.predict(test)\n",
    "    newDataFrame = pd.DataFrame({\"input\": test.tolist(), \"output\" : predictTree})\n",
    "    return newDataFrame\n",
    "\n",
    "test10000 = espirales(10000)\n",
    "testTopredict = np.array(test10000['input'].tolist())\n",
    "plotTest150 = comparationDataFrame(testTopredict, tree150)\n",
    "printData(plotTest150)\n",
    "\n",
    "plotTest600 = comparationDataFrame(testTopredict, tree600)\n",
    "printData(plotTest600)\n",
    "\n",
    "plotTest3000 = comparationDataFrame(testTopredict, tree3000)\n",
    "printData(plotTest3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "Dependencia con la longitud del conjunto de entrenamiento - Sobreajuste:\n",
    "\n",
    "Genere datasets usando el código \"diagonal\" desarrollado en la práctica de python (el otro conjunto desarrollado se llama \"paralelo\"), con C = 0.78 y d = 2. Genere un único conjunto de test con n = 10000. Genere 20 conjuntos de entrenamiento para cada uno de los siguientes valores de n: 125, 250, 500, 1000, 2000, 4000. Entrene árboles sobre estos conjuntos y guarde los resultados de error (1-accuracy) sobre los datos de entrenamiento y sobre el conjunto de test, como así también el tamaño del árbol (atributo tree_.node_count). En primer lugar genera una gráfica de las predicciones sobre los datos de test (plot x-y con colores para las clases) para un ejemplo de cada tamaño de conjunto de entrenamiento. Comente lo que se puede observar.\n",
    "También genere dos gráficas: la primer gráfica tiene el training error y test error, y la segunda la cantidad de nodos en el árbol, todos como función de la longitud del conjunto de entrenamiento (utilice siempre el promedio de los 20 conjuntos de cada longitud dada). Sugerencia: usar escala logarítmica en el eje x, de la cantidad de datos.\n",
    "\n",
    "Finalmente, repita todo el procedimiento completo usando como generador de datos el \"paralelo\". Incluya los resultados correspondientes en las mismas gráficas del diagonal. Discuta los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatorDataTree(distribution, values, count):\n",
    "    test = distribution(10000, 2, 0.78)\n",
    "    (Xtest, ytest),treeTest = toTreeClassifier(test)\n",
    "    nDF = dict()\n",
    "    nDFError = dict()\n",
    "    \n",
    "    for n in nValues:\n",
    "        nDF[n] = (([],[]),[])   # (([dataframes], [data train]), trees)\n",
    "        nDFError[n] = ([],[],[]) # ([training error], [test error], [count nodes]) \n",
    "        for countdf in range(countSets):\n",
    "                # Make DataFrame\n",
    "                diag = distribution(n, 2, 0.78)\n",
    "                (Xtrain, ytrain),tree = toTreeClassifier(diag)\n",
    "    \n",
    "                # Save DataFrame\n",
    "                ((dfs,trains), trees) = nDF[n]\n",
    "                dfs.append(diag)\n",
    "                trains.append((Xtrain, ytrain))\n",
    "                trees.append(tree)\n",
    "                nDF[n] = ((dfs,trains), trees)\n",
    "    \n",
    "                # Save Errors and nodes\n",
    "                (trainErrors, testErrors, countNodes) = nDFError[n]\n",
    "                nodes = tree.tree_.node_count\n",
    "                trainError = 1 - tree.score(Xtrain, ytrain)\n",
    "                testError = 1 - tree.score(Xtest, ytest)\n",
    "                trainErrors.append(trainError)\n",
    "                testErrors.append(testError)\n",
    "                countNodes.append(nodes)\n",
    "                nDFError[n] = (trainErrors, testErrors, countNodes)\n",
    "    return nDF, nDFError, ((Xtest, ytest),treeTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nValues = [125, 250, 500, 1000, 2000, 4000]\n",
    "countSets = 20\n",
    "nDiag, nDiagErr, testDiag = generatorDataTree(diagonales, nValues, countSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nValues:\n",
    "    (_,trees) = nDiag[n]\n",
    "    plotTest = comparationDataFrame(testDiag[0][0], trees[0])\n",
    "    printData(plotTest)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEscLog(valuesX, valuesY, labelY):\n",
    "    plt.figure()\n",
    "    plt.plot(valuesX, valuesY)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Cantidad de datos n')\n",
    "    plt.ylabel(labelY)\n",
    "    plt.title('Cantidad de nodos en función de cantidad de datos')\n",
    "    plt.show()\n",
    "\n",
    "promTrainErr = []\n",
    "promTestErr = []\n",
    "promNodes = []\n",
    "for n in nValues:\n",
    "    (trainErrors, testErrors, countNodes) = nDFError[n]\n",
    "    promTrainErr.append(sum(trainErrors)/countSets)\n",
    "    promTestErr.append(sum(testErrors)/countSets)\n",
    "    promNodes.append(sum(countNodes)/countSets)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nValues, promTrainErr, label='Train Error', color='red')\n",
    "plt.plot(nValues, promTestErr, label='Test Error', color='blue')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Cantidad de datos')\n",
    "plt.ylabel('Errores')\n",
    "plt.title('Errores en función de la cantidad de datos')\n",
    "plt.show()\n",
    "\n",
    "printEscLog(nValues, promNodes, 'Count nodes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nValues = [125, 250, 500, 1000, 2000, 4000]\n",
    "countSets = 20\n",
    "\n",
    "# Diagonales\n",
    "nParalel, nParalelErr, testParalel = generatorDataTree(paralelas, nValues, countSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nValues:\n",
    "    (_,trees) = nParalel[n]\n",
    "    plotTest = comparationDataFrame(testParalel[0][0], trees[0])\n",
    "    printData(plotTest)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promTrainErr = []\n",
    "promTestErr = []\n",
    "promNodes = []\n",
    "for n in nValues:\n",
    "    (trainErrors, testErrors, countNodes) = nDFError[n]\n",
    "    promTrainErr.append(sum(trainErrors)/countSets)\n",
    "    promTestErr.append(sum(testErrors)/countSets)\n",
    "    promNodes.append(sum(countNodes)/countSets)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nValues, promTrainErr, label='Train Error', color='red')\n",
    "plt.plot(nValues, promTestErr, label='Test Error', color='blue')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Cantidad de datos')\n",
    "plt.ylabel('Errores')\n",
    "plt.title('Errores en función de la cantidad de datos')\n",
    "plt.show()\n",
    "\n",
    "printEscLog(nValues, promNodes, 'Count nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Resistencia al ruido:\n",
    "\n",
    "Genere datasets con d = 5, n = 250 para el conjunto de entrenamiento y n = 10000 para el de test, variando el valor de C (overlapping de las clases) de 0.5 a 2.5 con incrementos de 0.5. Como en el punto anterior, para cada valor dado de C cree 20 conjuntos distintos de entrenamiento, pero uno solo de test. Genere una gráfica del test-error en función de C para el problema \"paralelo\" y el \"diagonal\" (sólo los promedios de los 20 conjuntos para cada valor de C). También incluya en la gráfica los valores mínimos que se piden en el opcional 3.1 (el que no haga el opcional me los puede pedir a mi). Todos los resultados de los dos problemas y el error mínimo en la misma gráfica. Discuta los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 opcional\n",
    "Puede calcular para cada valor de C cuál es el mínimo error que se puede conseguir? Cómo se comparan dichos valores con los obtenidos con el árbol? Obtenga una curva de error mínimo y agréguela a la gráfica anterior. Explique brevemente cómo obtuvo los valores mínimos.\n",
    "Hay varias maneras de hacerlo. Una simple es imaginando cuál es el clasificador ideal o de mínimo error para este problema (a ese clasificador se lo llama \"clasificador de Bayes\") y midiendo directamente sobre un conjunto de test grande (10000 puntos para d=5) cuántos puntos son mal clasificados por ese clasificador ideal. Para que verifiquen sus resultados, el error de Bayes para el diagonal con C=1.00 es 15.86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "Dimensionalidad:\n",
    "\n",
    "Genere datasets con C = 0.78, n = 250 para el conjunto de entrenamiento y n = 10000 para el de test, variando esta vez el valor de d según la siguiente lista: 2, 4, 8, 16, 32. Para cada valor de d cree 20 conjuntos distintos de entrenamiento, y uno solo de test. Genere una gráfica del train y test error en función de d para el problema \"paralelo\" y el \"diagonal\" (todos en la misma gráfica). Discuta los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "Opcional: Baje de los archivos al problema XOR. Grafique las clases. Observando el problema, indique cuál es el árbol más simple que clasifica correctamente todos los puntos. Aplique ahora un árbol con el siguiente setup DecisionTreeClassifier(criterion=\"entropy\",min_impurity_decrease=0.03,random_state=0,min_samples_leaf=5) \n",
    "sobre este problema, y explique el resultado obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo 5"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
